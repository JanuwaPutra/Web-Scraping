{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "# Setup WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Menjalankan di background\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# URL yang ingin di-scrape\n",
    "urls = [\n",
    "    \"https://jagasuara2024.org/main/rekapitulasi/gubernur/provinsi?id=74\"\n",
    "]\n",
    "\n",
    "# Fungsi untuk scrape data dari halaman\n",
    "def scrape_data(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Tunggu beberapa detik untuk memastikan halaman dimuat\n",
    "\n",
    "    # Ambil header kolom dari elemen <thead>\n",
    "    thead = driver.find_element(By.XPATH, '//table[@class=\"table-auto w-full text-center\"]/thead')\n",
    "    header_cols = thead.find_elements(By.XPATH, './/th')\n",
    "    headers = []\n",
    "\n",
    "    # Proses header kolom yang ada\n",
    "    for header in header_cols:\n",
    "        header_text = header.text.strip()\n",
    "        \n",
    "        # Cek apakah header tersebut berisi dua nama (dalam satu kolom)\n",
    "        links = header.find_elements(By.TAG_NAME, 'a')\n",
    "        if len(links) == 2:  # Jika ada dua kandidat\n",
    "            candidate_1 = links[0].text.strip()\n",
    "            candidate_2 = links[1].text.strip()\n",
    "            # Menambahkan nama kandidat dua kali di header untuk kolom baru\n",
    "            headers.append(f\"{candidate_1} - {candidate_2}\")\n",
    "            headers.append(f\"{candidate_1} - {candidate_2}\")  # Kolom baru dengan nama yang sama\n",
    "        elif header_text:  # Jika hanya ada satu nama atau teks biasa\n",
    "            headers.append(header_text)\n",
    "\n",
    "    # Ambil tabel\n",
    "    tabel = driver.find_element(By.XPATH, '//table[@class=\"table-auto w-full text-center\"]')\n",
    "    rows = tabel.find_elements(By.XPATH, './/tbody/tr')\n",
    "    \n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_elements(By.XPATH, './/td')\n",
    "        cols_data = []\n",
    "        for index, col in enumerate(cols):\n",
    "            text = col.text.strip()\n",
    "            if index == 0:  # Kolom pertama (Kabupaten/Kota) mengandung link\n",
    "                cols_data.append(text)\n",
    "            else:\n",
    "                cols_data.append(text)\n",
    "\n",
    "        data.append(cols_data)\n",
    "\n",
    "    return headers, data\n",
    "\n",
    "# Menyusun nama file berdasarkan URL\n",
    "def extract_province_id(url):\n",
    "    match = re.search(r'provinsi\\?id=(\\d+)', url)\n",
    "    return match.group(1) if match else \"unknown\"\n",
    "\n",
    "# Scrape data dari semua URL yang ditentukan\n",
    "all_data = []\n",
    "headers = []\n",
    "for url in urls:\n",
    "    page_headers, data = scrape_data(url)\n",
    "    headers = page_headers  # Ambil header hanya dari halaman pertama, asumsikan header sama untuk semua\n",
    "    all_data.extend(data)  # Gabungkan data dari setiap halaman\n",
    "\n",
    "# Ambil ID provinsi dari URL untuk menyesuaikan nama file\n",
    "province_id = extract_province_id(urls[0])\n",
    "filename = f\"Provinsi_{province_id}.csv\"  # Menyesuaikan nama file dengan ID provinsi\n",
    "\n",
    "# Menyimpan data ke CSV\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Menulis header yang diambil otomatis dari <thead>\n",
    "    writer.writerow( headers )  # Menambahkan kolom 'Province ID' dan 'Link'\n",
    "    \n",
    "    # Menulis data yang sudah diambil, dengan menyertakan province_id untuk setiap baris\n",
    "    for row in all_data:\n",
    "        writer.writerow(row)  # Menambahkan province_id ke setiap baris data\n",
    "\n",
    "print(f\"Data telah disimpan ke {filename}\")\n",
    "\n",
    "# Fungsi untuk scrape halaman utama dan ambil link kabupaten\n",
    "def scrape_main_page(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Tunggu beberapa detik untuk memastikan halaman dimuat\n",
    "\n",
    "    # Ambil tabel\n",
    "    table = driver.find_element(By.XPATH, '//table[@class=\"table-auto w-full text-center\"]')\n",
    "    rows = table.find_elements(By.XPATH, './/tbody/tr')\n",
    "\n",
    "    kabupaten_links = []\n",
    "\n",
    "    for row in rows:\n",
    "        kabupaten_name_col = row.find_element(By.XPATH, './/td[1]/a')\n",
    "        kabupaten_name = kabupaten_name_col.text.strip()\n",
    "        kabupaten_link = kabupaten_name_col.get_attribute('href')\n",
    "        kabupaten_links.append((kabupaten_name, kabupaten_link))\n",
    "\n",
    "    return kabupaten_links\n",
    "\n",
    "# Fungsi untuk scrape halaman kabupaten\n",
    "# Scrape halaman kabupaten\n",
    "def scrape_kabupaten_page(kabupaten_url):\n",
    "    driver.get(kabupaten_url)\n",
    "    time.sleep(5)  # Tunggu beberapa detik untuk memastikan halaman dimuat\n",
    "\n",
    "    # Ambil tabel dari halaman kabupaten\n",
    "    table = driver.find_element(By.XPATH, '//div[@class=\"flex flex-row justify-center\"]//table')\n",
    "    \n",
    "    # Ambil header (kolom) dari tabel\n",
    "    headers = table.find_elements(By.XPATH, './/thead//th')\n",
    "    header_names = []  # Pastikan variabel ini digunakan\n",
    "\n",
    "    for header in headers:\n",
    "        header_text = header.text.strip()\n",
    "        links = header.find_elements(By.TAG_NAME, 'a')\n",
    "        if len(links) == 2:  # Jika ada dua kandidat\n",
    "            candidate_1 = links[0].text.strip()\n",
    "            candidate_2 = links[1].text.strip()\n",
    "            header_names.append(f\"{candidate_1} - {candidate_2}\")\n",
    "            header_names.append(f\"{candidate_1} - {candidate_2}\")  # Kolom baru dengan nama yang sama\n",
    "        elif header_text:  # Jika hanya ada satu nama atau teks biasa\n",
    "            header_names.append(header_text)\n",
    "\n",
    "    # Ambil data (baris) dari tabel\n",
    "    rows = table.find_elements(By.XPATH, './/tbody/tr')\n",
    "    data = []\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_elements(By.XPATH, './/td')\n",
    "        cols_data = []\n",
    "        links_data = []  # Menyimpan link URL untuk setiap baris\n",
    "        for index, col in enumerate(cols):\n",
    "            text = col.text.strip()\n",
    "            if index == 0:  # Kolom pertama (Kabupaten/Kota) mengandung link\n",
    "                link_kecamatan = col.find_element(By.TAG_NAME, 'a').get_attribute('href') if col.find_elements(By.TAG_NAME, 'a') else \"\"\n",
    "                links_data.append(link_kecamatan)  # Menambahkan link\n",
    "                cols_data.append(text)\n",
    "            else:\n",
    "                cols_data.append(text)\n",
    "\n",
    "        cols_data.extend(links_data)  # Gabungkan data dengan link\n",
    "        data.append(cols_data)\n",
    "\n",
    "    return header_names, data\n",
    "\n",
    "# Ambil link kabupaten dari halaman utama\n",
    "kabupaten_links = scrape_main_page(url)\n",
    "\n",
    "# Loop untuk setiap link kabupaten dan scrape halaman detailnya\n",
    "for kabupaten_name, kabupaten_link in kabupaten_links:\n",
    "    print(f\"Scraping {kabupaten_name}...\")\n",
    "    headers, data = scrape_kabupaten_page(kabupaten_link)  # Pastikan header dari fungsi ini digunakan\n",
    "\n",
    "    # Membuat nama file CSV berdasarkan nama kabupaten\n",
    "    filename = f\"{kabupaten_name} data.csv\"\n",
    "    \n",
    "    \n",
    "    # Membuat nama folder dan memastikan folder tersebut ada\n",
    "    folder_name = \"kabupaten Atau Kota\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # Membuat nama file CSV berdasarkan nama kabupaten di dalam folder\n",
    "    filename = os.path.join(folder_name, f\"{kabupaten_name} data.csv\")\n",
    "\n",
    "    # Menyimpan data ke CSV\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Menulis header yang diambil dari elemen <th>\n",
    "        writer.writerow(headers + ['Link'])  # Gunakan header dari fungsi `scrape_kabupaten_page`\n",
    "        \n",
    "        # Menulis data\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "        print(f\"Data untuk kabupaten {kabupaten_name} telah disimpan ke {filename}\")\n",
    "\n",
    "# Tutup browser setelah selesai\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Folder input dan output\n",
    "input_folder = \"kabupaten Atau Kota\"\n",
    "output_folder = \"kecamatan\"\n",
    "\n",
    "# Setup Selenium WebDriver\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Jalankan browser di mode headless\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Membuat folder output jika belum ada\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Membaca semua file CSV dalam folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".csv\"):  # Hanya memproses file CSV\n",
    "        input_csv = os.path.join(input_folder, file_name)\n",
    "\n",
    "        # Membaca isi file CSV\n",
    "        with open(input_csv, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                kecamatan_name = row[\"Kecamatan\"]\n",
    "                link = row[\"Link\"]\n",
    "\n",
    "                # Buka halaman link\n",
    "                driver.get(link)\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"table-auto\"))\n",
    "                )\n",
    "\n",
    "                # Scraping data tabel\n",
    "                table = driver.find_element(By.CLASS_NAME, \"table-auto\")\n",
    "                \n",
    "                # Ambil header (kolom) dari tabel\n",
    "                headers = table.find_elements(By.XPATH, './/thead//th')\n",
    "                header_names = []  # Variabel untuk menyimpan nama header\n",
    "\n",
    "                for header in headers:\n",
    "                    header_text = header.text.strip()\n",
    "                    links = header.find_elements(By.TAG_NAME, 'a')\n",
    "                    if len(links) == 2:  # Jika ada dua kandidat\n",
    "                        candidate_1 = links[0].text.strip()\n",
    "                        candidate_2 = links[1].text.strip()\n",
    "                        header_names.append(f\"{candidate_1} - {candidate_2}\")\n",
    "                        header_names.append(f\"{candidate_1} - {candidate_2}\")  # Kolom baru dengan nama yang sama\n",
    "                    elif header_text:  # Jika hanya ada satu nama atau teks biasa\n",
    "                        header_names.append(header_text)\n",
    "\n",
    "                # Tambahkan kolom \"Link\" ke dalam header jika belum ada\n",
    "                if \"Link\" not in header_names:\n",
    "                    header_names.append(\"Link\")\n",
    "\n",
    "                rows = []\n",
    "\n",
    "                # Iterasi setiap baris data di tabel\n",
    "                for tr in table.find_elements(By.XPATH, \".//tbody/tr\"):\n",
    "                    row_data = [td.text.strip() for td in tr.find_elements(By.XPATH, \".//td\")]\n",
    "\n",
    "                    # Cari link dari elemen <a> di kolom kecamatan\n",
    "                    link_element = tr.find_element(By.XPATH, \".//td/a\")\n",
    "                    link_url = link_element.get_attribute(\"href\")\n",
    "\n",
    "                    # Tambahkan link ke baris data\n",
    "                    row_data.append(link_url)\n",
    "                    rows.append(row_data)\n",
    "\n",
    "                # Membuat folder berdasarkan nama kecamatan di dalam folder output\n",
    "                kecamatan_folder = os.path.join(output_folder, file_name.replace('.csv', '').replace(' ', '_'))\n",
    "                os.makedirs(kecamatan_folder, exist_ok=True)\n",
    "\n",
    "                # Menyimpan data ke CSV di dalam folder kecamatan\n",
    "                output_csv = os.path.join(kecamatan_folder, f\"{kecamatan_name.replace(' ', '_')}.csv\")\n",
    "                with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as out_file:\n",
    "                    writer = csv.writer(out_file)\n",
    "                    writer.writerow(header_names)  # Header\n",
    "                    writer.writerows(rows)  # Data\n",
    "\n",
    "                print(f\"Data untuk {kecamatan_name} telah disimpan di {output_csv}\")\n",
    "\n",
    "# Tutup browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Folder input dan output\n",
    "input_folder = \"kecamatan\"  # Folder tempat file CSV input\n",
    "output_folder = \"kelurahan\"  # Folder untuk menyimpan hasil scraping\n",
    "\n",
    "# Setup Selenium WebDriver\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Jalankan browser di mode headless\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Membuat folder output jika belum ada\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Menelusuri semua folder dan subfolder untuk mencari file CSV\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".csv\"):  # Hanya memproses file CSV\n",
    "            input_csv = os.path.join(root, file_name)\n",
    "\n",
    "            # Membaca isi file CSV\n",
    "            with open(input_csv, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                for row in reader:\n",
    "                    kecamatan_name = row[\"Kelurahan\"]\n",
    "                    link = row[\"Link\"]\n",
    "\n",
    "                    # Buka halaman link\n",
    "                    driver.get(link)\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CLASS_NAME, \"table-auto\"))\n",
    "                    )\n",
    "\n",
    "                    # Scraping data tabel\n",
    "                    table = driver.find_element(By.CLASS_NAME, \"table-auto\")\n",
    "                    \n",
    "                    # Ambil header (kolom) dari tabel\n",
    "                    headers = table.find_elements(By.XPATH, './/thead//th')\n",
    "                    header_names = []  # Variabel untuk menyimpan nama header\n",
    "\n",
    "                    for header in headers:\n",
    "                        header_text = header.text.strip()\n",
    "                        links = header.find_elements(By.TAG_NAME, 'a')\n",
    "                        if len(links) == 2:  # Jika ada dua kandidat\n",
    "                            candidate_1 = links[0].text.strip()\n",
    "                            candidate_2 = links[1].text.strip()\n",
    "                            header_names.append(f\"{candidate_1} - {candidate_2}\")\n",
    "                            header_names.append(f\"{candidate_1} - {candidate_2}\")  # Kolom baru dengan nama yang sama\n",
    "                        elif header_text:  # Jika hanya ada satu nama atau teks biasa\n",
    "                            header_names.append(header_text)\n",
    "\n",
    "                    # Tambahkan kolom \"Link\" ke dalam header jika belum ada\n",
    "                    if \"Link\" not in header_names:\n",
    "                        header_names.append(\"Link\")\n",
    "\n",
    "                    rows = []\n",
    "\n",
    "                    # Iterasi setiap baris data di tabel\n",
    "                    for tr in table.find_elements(By.XPATH, \".//tbody/tr\"):\n",
    "                        row_data = [td.text.strip() for td in tr.find_elements(By.XPATH, \".//td\")]\n",
    "\n",
    "                        # Cari link dari elemen <a> di kolom kecamatan\n",
    "                        link_element = tr.find_element(By.XPATH, \".//td/a\")\n",
    "                        link_url = link_element.get_attribute(\"href\")\n",
    "\n",
    "                        # Tambahkan link ke baris data\n",
    "                        row_data.append(link_url)\n",
    "                        rows.append(row_data)\n",
    "\n",
    "                    # Membuat folder berdasarkan nama CSV dari folder input di dalam folder output\n",
    "                    # Nama folder berdasarkan nama file CSV (misalnya KAB. BOMBANA_DATA)\n",
    "                    kecamatan_folder = os.path.join(output_folder, f\"{file_name.replace('.csv', '').replace(' ', '_')}_DATA\")\n",
    "                    os.makedirs(kecamatan_folder, exist_ok=True)\n",
    "\n",
    "                    # Menyimpan data ke CSV di dalam folder kecamatan\n",
    "                    output_csv = os.path.join(kecamatan_folder, f\"{kecamatan_name.replace(' ', '_')}.csv\")\n",
    "                    with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as out_file:\n",
    "                        writer = csv.writer(out_file)\n",
    "                        writer.writerow(header_names)  # Header\n",
    "                        writer.writerows(rows)  # Data\n",
    "\n",
    "                    print(f\"Data untuk {kecamatan_name} telah disimpan di {output_csv}\")\n",
    "\n",
    "# Tutup browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
